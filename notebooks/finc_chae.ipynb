{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "df = pandas.read_csv(r\"C:\\Users\\91938\\Desktop\\1st_project\\artifacts\\train.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'carat', 'cut', 'color', 'clarity', 'depth', 'table', 'x', 'y',\n",
       "       'z', 'price'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'carat', 'cut', 'color', 'clarity', 'depth', 'table', 'x', 'y',\n",
       "       'z', 'price'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.1 71.6\n"
     ]
    }
   ],
   "source": [
    "print(df[\"depth\"].min(),df[\"depth\"].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6.68,  8.25,  6.76,  7.3 ,  4.4 ,  6.31,  4.33,  4.34,  4.76,\n",
       "        7.43,  6.94,  4.48,  5.18,  3.98,  6.91,  6.7 ,  5.29,  5.7 ,\n",
       "        4.84,  6.89,  5.38,  6.36,  4.79,  5.67,  5.8 ,  6.67,  4.28,\n",
       "        5.9 ,  5.24,  5.1 ,  6.59,  4.31,  6.28,  6.38,  3.94,  4.13,\n",
       "        6.5 ,  4.36,  5.36,  6.97,  6.49,  6.73,  7.77,  5.09,  5.85,\n",
       "        4.7 ,  6.44,  5.78,  4.78,  5.21,  4.25,  8.13,  6.46,  6.79,\n",
       "        4.3 ,  4.68,  5.37,  5.66,  6.51,  5.77,  5.74,  6.92,  6.87,\n",
       "        5.34,  4.82,  7.38,  5.08,  5.82,  4.32,  4.81,  4.37,  5.14,\n",
       "        8.08,  4.69,  6.6 ,  5.81,  6.98,  6.74,  5.75,  5.  ,  6.19,\n",
       "        4.59,  6.39,  6.26,  6.22,  6.55,  5.4 ,  5.72,  6.21,  6.32,\n",
       "        4.72,  4.67,  6.33,  5.03,  6.47,  8.01,  6.9 ,  8.16,  4.6 ,\n",
       "        7.74,  6.64,  5.92,  4.35,  6.17,  6.05,  5.71,  5.57,  4.23,\n",
       "        5.33,  4.8 ,  5.96,  4.39,  7.49,  8.21,  5.39,  8.07,  5.27,\n",
       "        7.54,  5.69,  7.33,  6.82,  5.31,  6.3 ,  6.16,  6.48,  6.52,\n",
       "        4.74,  7.09,  4.77,  4.47,  6.56,  4.18,  8.4 ,  4.38,  7.  ,\n",
       "        7.27,  7.07,  6.14,  8.34,  6.96,  7.36,  7.98,  6.57,  6.03,\n",
       "        6.42,  7.32,  5.61,  6.29,  4.07,  6.62,  5.22,  7.23,  7.21,\n",
       "        7.97,  7.45,  7.31,  8.06,  7.51,  7.41,  4.29,  5.3 ,  4.83,\n",
       "        6.63,  5.99,  5.84,  6.34,  6.71,  5.79,  5.26,  5.52,  7.08,\n",
       "        4.51,  6.15,  4.54,  5.83,  5.32,  8.46,  7.78,  8.03,  4.43,\n",
       "        7.62,  4.45,  5.16,  6.77,  8.15,  5.76,  4.63,  8.22,  5.54,\n",
       "        4.75,  7.72,  5.97,  7.26,  7.19,  5.15,  4.95,  8.61,  8.37,\n",
       "        5.02,  8.36,  6.54,  4.41,  5.68,  5.41,  5.07,  5.89,  8.23,\n",
       "        7.52,  6.2 ,  4.49,  5.93,  8.12,  5.11,  6.18,  5.13,  5.23,\n",
       "        5.88,  7.28,  6.4 ,  5.04,  5.95,  5.53,  6.35,  6.72,  8.24,\n",
       "        4.64,  6.41,  8.1 ,  4.46,  7.53,  6.53,  6.37,  7.64,  5.17,\n",
       "        3.9 ,  4.85,  6.  ,  4.42,  7.44,  4.97,  4.58,  7.42,  4.93,\n",
       "        8.17,  7.4 ,  4.56,  3.99,  5.64,  5.44,  4.73,  6.45,  4.06,\n",
       "        6.85,  7.96,  6.81,  7.2 ,  3.91,  5.2 ,  7.99,  4.62,  6.13,\n",
       "        8.2 ,  7.66,  7.35,  6.06,  6.25,  5.19,  6.84,  4.26,  5.06,\n",
       "        8.09,  4.5 ,  6.93,  7.59,  7.12,  4.01,  6.78,  6.08,  6.27,\n",
       "        6.09,  4.27,  5.6 ,  5.73,  7.04,  7.03,  5.63,  4.52,  5.28,\n",
       "        7.37,  7.06,  8.48,  6.8 ,  7.14,  5.65,  7.9 ,  5.56,  6.23,\n",
       "        6.61,  7.34,  6.66,  5.12,  6.01,  4.55,  6.11,  8.18,  5.86,\n",
       "        6.43,  4.11,  8.04,  5.35,  6.58,  5.05,  4.24,  4.86,  7.69,\n",
       "        4.44,  5.48,  6.86,  7.01,  4.09,  5.25,  4.15,  4.65,  4.03,\n",
       "        7.48,  7.85,  4.66,  6.65,  7.73,  4.12,  8.11,  5.43,  4.57,\n",
       "        4.05,  8.33,  5.94,  8.27,  5.46,  4.71,  4.1 ,  6.12,  7.1 ,\n",
       "        5.59,  6.24,  7.68,  4.53,  6.88,  6.75,  7.29,  7.87,  5.5 ,\n",
       "        7.46,  7.39,  8.49,  7.57,  6.95,  7.24,  7.89,  5.91,  4.87,\n",
       "        6.07,  5.42,  5.58,  8.26,  8.38,  6.83,  8.32,  4.  ,  5.45,\n",
       "        7.5 ,  4.88,  6.04,  5.98,  8.19,  3.97,  7.56,  8.53,  4.94,\n",
       "        7.67,  6.69,  8.  ,  4.08,  7.47,  4.16,  8.3 ,  3.95,  7.05,\n",
       "        5.87,  6.1 ,  7.7 ,  7.6 ,  7.16,  4.61,  5.01,  6.99,  7.58,\n",
       "        6.02,  8.43,  4.14,  7.93,  5.62,  8.5 ,  8.29,  8.54,  8.41,\n",
       "        4.2 ,  4.96,  7.88,  4.9 ,  8.14,  8.31,  7.25,  8.44,  8.35,\n",
       "        8.05,  7.61,  4.21,  7.22,  4.02,  8.02,  7.02,  4.22,  8.28,\n",
       "        4.19,  4.04,  7.55,  7.18,  7.11,  5.51,  8.58,  8.65,  8.68,\n",
       "        7.84,  8.42,  3.78,  4.91,  4.17,  4.98,  7.65,  3.93,  5.47,\n",
       "        7.94,  7.76,  3.96,  8.47,  3.89,  7.91,  8.45,  4.99,  5.49,\n",
       "        8.56,  7.63,  4.89,  4.92,  7.75,  3.72,  7.79,  3.92,  3.86,\n",
       "        8.73,  5.55,  7.15,  7.82,  7.13,  8.39,  7.95,  8.52,  9.24,\n",
       "        7.17,  3.77,  7.71,  8.81,  8.57,  8.64,  9.02,  7.86,  8.66,\n",
       "        7.8 ,  8.55,  8.51,  7.83,  3.81,  8.82,  8.78,  7.92,  7.81,\n",
       "        8.59,  3.87,  8.71,  8.85,  8.6 ,  3.79,  0.  ,  9.3 ,  9.31,\n",
       "        8.84,  9.46,  3.71,  8.87,  8.62,  8.86,  3.88,  8.79,  3.84,\n",
       "        8.77,  8.67,  3.75,  8.9 ,  3.85,  9.36,  8.69, 10.01,  3.8 ,\n",
       "        8.76,  8.83,  9.26])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"y\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.linear_model._base.LinearRegression'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator LinearRegression from version 1.3.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = joblib.load(r\"C:\\Users\\91938\\Desktop\\1st_project\\artifacts\\model.pkl\")\n",
    "print(type(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.linear_model._base.LinearRegression'>\n"
     ]
    }
   ],
   "source": [
    "print(type(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "\n",
    "model = joblib.load(r\"C:\\Users\\91938\\Desktop\\1st_project\\artifacts\\model.pkl\")\n",
    "if hasattr(model, 'feature_names_'):\n",
    "    feature_order = model.feature_names_\n",
    "    print(\"Order of independent features:\", feature_order)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature names not available.\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "model = joblib.load(r\"C:\\Users\\91938\\Desktop\\1st_project\\artifacts\\model.pkl\")\n",
    "\n",
    "# Check for 'get_feature_names_out' method\n",
    "if hasattr(model, 'get_feature_names_out'):\n",
    "    feature_order = model.get_feature_names_out()\n",
    "    print(\"Order of independent features:\", feature_order)\n",
    "else:\n",
    "    print(\"Feature names not available.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
